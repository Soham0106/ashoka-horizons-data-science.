{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f59649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "X_prep_hours = np . array ([0.5 , 1.0 , 1.5 , 2.0 , 2.5 , 3.0 , 3.5 , 4.0 , 4.5 ,5.0]) . reshape ( -1 , 1)\n",
    "Y_pass_fail = np . array ([0 , 0 , 0 , 0 , 1 , 0 , 1 , 1 , 1 , 1])\n",
    "model=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c222d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Manual Probabilities [[0.01798621]\n",
      " [0.04742587]\n",
      " [0.11920292]\n",
      " [0.26894142]\n",
      " [0.5       ]\n",
      " [0.73105858]\n",
      " [0.88079708]\n",
      " [0.95257413]\n",
      " [0.98201379]\n",
      " [0.99330715]]\n",
      "Classes [[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Manual Accuracy 0.9\n"
     ]
    }
   ],
   "source": [
    "z = 2 * X_prep_hours - 5\n",
    "pass_X=1/(1+np.exp(-z))\n",
    "y2=(pass_X>=0.5).astype(int)\n",
    "prob2=(y2.flatten()==Y_pass_fail).sum()\n",
    "acc2=prob2/len(Y_pass_fail)\n",
    "print()\n",
    "print(\"Manual Probabilities\",pass_X)\n",
    "print(\"Classes\",y2)\n",
    "print(\"Manual Accuracy\",acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3079b6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient [[1.22396473]]\n",
      "Intercept [-3.36638058]\n",
      "[[0.94016126 0.05983874]\n",
      " [0.89495794 0.10504206]\n",
      " [0.82206973 0.17793027]\n",
      " [0.71472641 0.28527359]\n",
      " [0.57602309 0.42397691]\n",
      " [0.42421019 0.57578981]\n",
      " [0.28546838 0.71453162]\n",
      " [0.17807002 0.82192998]\n",
      " [0.10513189 0.89486811]\n",
      " [0.05989249 0.94010751]]\n",
      "Accuracy 0.8\n",
      "TN FP\n",
      "FN TP\n",
      "Confusion Matrix:\n",
      " [[4 1]\n",
      " [1 4]]\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_prep_hours,Y_pass_fail)\n",
    "y1=model.predict(X_prep_hours)\n",
    "coefficient=model.coef_\n",
    "intercept=model.intercept_\n",
    "print(\"Coefficient\",coefficient)\n",
    "print(\"Intercept\",intercept)\n",
    "prob1=model.predict_proba(X_prep_hours)\n",
    "print(prob1)\n",
    "acc1=accuracy_score(Y_pass_fail,y1)\n",
    "print(\"Accuracy\",acc1)\n",
    "print(\"TN\",\"FP\")\n",
    "print(\"FN\",\"TP\")\n",
    "conf_matrix = confusion_matrix(Y_pass_fail, y1)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eabba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On a scale of 1, acc1 and acc2 tells with how much accuracy is the model predicting correct values, based on prediction accuracy it makes.\n",
    "#Confusion matrix tells the number of True Negatives, False Positives in the first row, and in the second row, it tels number of False Negatives and True Positives\n",
    "#True Negatives-Number of correct negative predictions\n",
    "#False Positives-Number of incorrect positive predictions\n",
    "#False Negatives-Number of incorrect negative predictions\n",
    "#True Positives-Number of correct positive predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "horizons25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
